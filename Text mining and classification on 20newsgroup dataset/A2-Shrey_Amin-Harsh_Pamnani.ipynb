{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-2 (CSCI-5901)\n",
    "\n",
    "### Shrey Amin - B00822245\n",
    "### Harsh Pamnani - B00802614"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "\n",
    "Importing all the required libraries: nltk, pandas, numpy, and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\harsh pamnani\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (3.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\harsh pamnani\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 20 news group dataset\n",
    "\n",
    "Loading the dataset of 20 news group dataset having only 4 categories: alt.atheism, talk.religion.misc, comp.graphics, and sci.space. After that, printing the dataset size, target size, and target lables of the news group dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size is   :  (3387,)\n",
      "Target size is    :  (3387,)\n",
      "Target labels are :  [0 1 1 ... 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset with only 4 categories\n",
    "filterCategories=['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_data = fetch_20newsgroups(subset='all', shuffle=True, categories=filterCategories)\n",
    "print(\"Dataset size is   : \",newsgroups_data.filenames.shape)\n",
    "print(\"Target size is    : \",newsgroups_data.target.shape)\n",
    "print(\"Target labels are : \",newsgroups_data.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: healta@saturn.wwc.edu (Tammy R Healy)\n",
      "Subject: Re: who are we to judge, Bobby?\n",
      "Lines: 38\n",
      "Organization: Walla Walla College\n",
      "Lines: 38\n",
      "\n",
      "In article <1993Apr14.213356.22176@ultb.isc.rit.edu> snm6394@ultb.isc.rit.edu (S.N. Mozumder ) writes:\n",
      ">From: snm6394@ultb.isc.rit.edu (S.N. Mozumder )\n",
      ">Subject: Re: who are we to judge, Bobby?\n",
      ">Date: Wed, 14 Apr 1993 21:33:56 GMT\n",
      ">In article <healta.56.734556346@saturn.wwc.edu> healta@saturn.wwc.edu (TAMMY R HEALY) writes:\n",
      ">>Bobby,\n",
      ">>\n",
      ">>I would like to take the liberty to quote from a Christian writer named \n",
      ">>Ellen G. White.  I hope that what she said will help you to edit your \n",
      ">>remarks in this group in the future.\n",
      ">>\n",
      ">>\"Do not set yourself as a standard.  Do not make your opinions, your views \n",
      ">>of duty, your interpretations of scripture, a criterion for others and in \n",
      ">>your heart condemn them if they do not come up to your ideal.\"\n",
      ">>                         Thoughts Fromthe Mount of Blessing p. 124\n",
      ">>\n",
      ">>I hope quoting this doesn't make the atheists gag, but I think Ellen White \n",
      ">>put it better than I could.\n",
      ">> \n",
      ">>Tammy\n",
      ">\n",
      ">Point?\n",
      ">\n",
      ">Peace,\n",
      ">\n",
      ">Bobby Mozumder\n",
      ">\n",
      "My point is that you set up your views as the only way to believe.  Saying \n",
      "that all eveil in this world is caused by atheism is ridiculous and \n",
      "counterproductive to dialogue in this newsgroups.  I see in your posts a \n",
      "spirit of condemnation of the atheists in this newsgroup bacause they don'\n",
      "t believe exactly as you do.  If you're here to try to convert the atheists \n",
      "here, you're failing miserably.  Who wants to be in position of constantly \n",
      "defending themselves agaist insulting attacks, like you seem to like to do?!\n",
      "I'm sorry you're so blind that you didn't get the messgae in the quote, \n",
      "everyone else has seemed to.\n",
      "\n",
      "Tammy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replacing all the new lines of the each document and creating a list for the same.\n",
    "for i in range(len(newsgroups_data)):\n",
    "    newsgroups_data.data[i]=\"\\n\".join(newsgroups_data.data[i].split(\"\\n\"))\n",
    "\n",
    "print(newsgroups_data.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 Collocation extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1-a Tokenize the words\n",
    "\n",
    "We have tokenized each news article into words using \"word_tokenize\" method from nltk library. \"tokens_words_for_newsgroups\" list will contain the words for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token words generated for 3387 documents.\n",
      "Token words for first documents are : \n",
      "['From', ':', 'healta', '@', 'saturn.wwc.edu', '(', 'Tammy', 'R', 'Healy', ')', 'Subject', ':', 'Re', ':', 'who', 'are', 'we', 'to', 'judge', ',', 'Bobby', '?', 'Lines', ':', '38', 'Organization', ':', 'Walla', 'Walla', 'College', 'Lines', ':', '38', 'In', 'article', '<', '1993Apr14.213356.22176', '@', 'ultb.isc.rit.edu', '>', 'snm6394', '@', 'ultb.isc.rit.edu', '(', 'S.N', '.', 'Mozumder', ')', 'writes', ':', '>', 'From', ':', 'snm6394', '@', 'ultb.isc.rit.edu', '(', 'S.N', '.', 'Mozumder', ')', '>', 'Subject', ':', 'Re', ':', 'who', 'are', 'we', 'to', 'judge', ',', 'Bobby', '?', '>', 'Date', ':', 'Wed', ',', '14', 'Apr', '1993', '21:33:56', 'GMT', '>', 'In', 'article', '<', 'healta.56.734556346', '@', 'saturn.wwc.edu', '>', 'healta', '@', 'saturn.wwc.edu', '(', 'TAMMY', 'R', 'HEALY', ')', 'writes', ':', '>', '>', 'Bobby', ',', '>', '>', '>', '>', 'I', 'would', 'like', 'to', 'take', 'the', 'liberty', 'to', 'quote', 'from', 'a', 'Christian', 'writer', 'named', '>', '>', 'Ellen', 'G.', 'White', '.', 'I', 'hope', 'that', 'what', 'she', 'said', 'will', 'help', 'you', 'to', 'edit', 'your', '>', '>', 'remarks', 'in', 'this', 'group', 'in', 'the', 'future', '.', '>', '>', '>', '>', \"''\", 'Do', 'not', 'set', 'yourself', 'as', 'a', 'standard', '.', 'Do', 'not', 'make', 'your', 'opinions', ',', 'your', 'views', '>', '>', 'of', 'duty', ',', 'your', 'interpretations', 'of', 'scripture', ',', 'a', 'criterion', 'for', 'others', 'and', 'in', '>', '>', 'your', 'heart', 'condemn', 'them', 'if', 'they', 'do', 'not', 'come', 'up', 'to', 'your', 'ideal', '.', \"''\", '>', '>', 'Thoughts', 'Fromthe', 'Mount', 'of', 'Blessing', 'p.', '124', '>', '>', '>', '>', 'I', 'hope', 'quoting', 'this', 'does', \"n't\", 'make', 'the', 'atheists', 'gag', ',', 'but', 'I', 'think', 'Ellen', 'White', '>', '>', 'put', 'it', 'better', 'than', 'I', 'could', '.', '>', '>', '>', '>', 'Tammy', '>', '>', 'Point', '?', '>', '>', 'Peace', ',', '>', '>', 'Bobby', 'Mozumder', '>', 'My', 'point', 'is', 'that', 'you', 'set', 'up', 'your', 'views', 'as', 'the', 'only', 'way', 'to', 'believe', '.', 'Saying', 'that', 'all', 'eveil', 'in', 'this', 'world', 'is', 'caused', 'by', 'atheism', 'is', 'ridiculous', 'and', 'counterproductive', 'to', 'dialogue', 'in', 'this', 'newsgroups', '.', 'I', 'see', 'in', 'your', 'posts', 'a', 'spirit', 'of', 'condemnation', 'of', 'the', 'atheists', 'in', 'this', 'newsgroup', 'bacause', 'they', \"don'\", 't', 'believe', 'exactly', 'as', 'you', 'do', '.', 'If', 'you', \"'re\", 'here', 'to', 'try', 'to', 'convert', 'the', 'atheists', 'here', ',', 'you', \"'re\", 'failing', 'miserably', '.', 'Who', 'wants', 'to', 'be', 'in', 'position', 'of', 'constantly', 'defending', 'themselves', 'agaist', 'insulting', 'attacks', ',', 'like', 'you', 'seem', 'to', 'like', 'to', 'do', '?', '!', 'I', \"'m\", 'sorry', 'you', \"'re\", 'so', 'blind', 'that', 'you', 'did', \"n't\", 'get', 'the', 'messgae', 'in', 'the', 'quote', ',', 'everyone', 'else', 'has', 'seemed', 'to', '.', 'Tammy']\n"
     ]
    }
   ],
   "source": [
    "tokens_words_for_newsgroups=[]\n",
    "for i in range(len(newsgroups_data.data)):\n",
    "    tokens_words_for_newsgroups.append(word_tokenize(newsgroups_data.data[i]))\n",
    "\n",
    "print(\"Token words generated for\", len(tokens_words_for_newsgroups), \"documents.\")    \n",
    "print(\"Token words for first documents are : \")\n",
    "print(tokens_words_for_newsgroups[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataset\n",
    "\n",
    "Cleaning the dataset before identifying bigram collocation to identify meaningful bigram collocations. For cleaning the dataset, we have removed stopwords, non-alphabetic characters and token words with length less than 2 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned tokens for first document are :\n",
      " ['from', 'healta', 'tammy', 'healy', 'subject', 'judge', 'bobby', 'lines', 'organization', 'walla', 'walla', 'college', 'lines', 'article', 'mozumder', 'writes', 'from', 'mozumder', 'subject', 'judge', 'bobby', 'date', 'wed', 'apr', 'gmt', 'article', 'healta', 'tammy', 'healy', 'writes', 'bobby', 'would', 'like', 'take', 'liberty', 'quote', 'christian', 'writer', 'named', 'ellen', 'white', 'hope', 'said', 'help', 'edit', 'remarks', 'group', 'future', 'set', 'standard', 'make', 'opinions', 'views', 'duty', 'interpretations', 'scripture', 'criterion', 'others', 'heart', 'condemn', 'come', 'ideal', 'thoughts', 'fromthe', 'mount', 'blessing', 'hope', 'quoting', 'make', 'atheists', 'gag', 'think', 'ellen', 'white', 'put', 'better', 'could', 'tammy', 'point', 'peace', 'bobby', 'mozumder', 'point', 'set', 'views', 'way', 'believe', 'saying', 'eveil', 'world', 'caused', 'atheism', 'ridiculous', 'counterproductive', 'dialogue', 'newsgroups', 'see', 'posts', 'spirit', 'condemnation', 'atheists', 'newsgroup', 'bacause', 'believe', 'exactly', 'try', 'convert', 'atheists', 'failing', 'miserably', 'who', 'wants', 'position', 'constantly', 'defending', 'agaist', 'insulting', 'attacks', 'like', 'seem', 'like', 'sorry', 'blind', 'get', 'messgae', 'quote', 'everyone', 'else', 'seemed', 'tammy']\n"
     ]
    }
   ],
   "source": [
    "newsgroup_cleaned_tokens = []\n",
    "stop_words_english = set(stopwords.words(\"english\"))\n",
    "\n",
    "for i in range(len(tokens_words_for_newsgroups)):\n",
    "    temp_words_list = []\n",
    "    for word in tokens_words_for_newsgroups[i]:\n",
    "        if ((word not in stop_words_english) and (word.isalpha()) and (len(word) > 2)):\n",
    "            temp_words_list.append(word.lower())\n",
    "    newsgroup_cleaned_tokens.append(temp_words_list)\n",
    "\n",
    "print(\"Cleaned tokens for first document are :\\n\", newsgroup_cleaned_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-speech(POS) tagging\n",
    "\n",
    "Performed POS tagging on generated token of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging generated for 3387 documents\n",
      "Pos-tagged words for first document are :\n",
      " [('from', 'IN'), ('healta', 'JJ'), ('tammy', 'NN'), ('healy', 'NN'), ('subject', 'JJ'), ('judge', 'NN'), ('bobby', 'NN'), ('lines', 'NNS'), ('organization', 'NN'), ('walla', 'NN'), ('walla', 'NN'), ('college', 'NN'), ('lines', 'NNS'), ('article', 'NN'), ('mozumder', 'NN'), ('writes', 'VBZ'), ('from', 'IN'), ('mozumder', 'NN'), ('subject', 'NN'), ('judge', 'NN'), ('bobby', 'NN'), ('date', 'NN'), ('wed', 'VBD'), ('apr', 'JJ'), ('gmt', 'NN'), ('article', 'NN'), ('healta', 'NN'), ('tammy', 'NN'), ('healy', 'NN'), ('writes', 'VBZ'), ('bobby', 'RB'), ('would', 'MD'), ('like', 'VB'), ('take', 'VB'), ('liberty', 'JJ'), ('quote', 'NN'), ('christian', 'JJ'), ('writer', 'NN'), ('named', 'VBN'), ('ellen', 'IN'), ('white', 'JJ'), ('hope', 'NN'), ('said', 'VBD'), ('help', 'NN'), ('edit', 'NN'), ('remarks', 'NNS'), ('group', 'NN'), ('future', 'NN'), ('set', 'VBN'), ('standard', 'JJ'), ('make', 'VBP'), ('opinions', 'NNS'), ('views', 'NNS'), ('duty', 'NN'), ('interpretations', 'NNS'), ('scripture', 'VBP'), ('criterion', 'NN'), ('others', 'NNS'), ('heart', 'NN'), ('condemn', 'VBZ'), ('come', 'JJ'), ('ideal', 'JJ'), ('thoughts', 'NNS'), ('fromthe', 'VBP'), ('mount', 'NN'), ('blessing', 'VBG'), ('hope', 'NN'), ('quoting', 'VBG'), ('make', 'VB'), ('atheists', 'NNS'), ('gag', 'VB'), ('think', 'VBP'), ('ellen', 'VBN'), ('white', 'JJ'), ('put', 'NN'), ('better', 'RBR'), ('could', 'MD'), ('tammy', 'VB'), ('point', 'VB'), ('peace', 'NN'), ('bobby', 'NN'), ('mozumder', 'NN'), ('point', 'NN'), ('set', 'VBN'), ('views', 'NNS'), ('way', 'NN'), ('believe', 'VBP'), ('saying', 'VBG'), ('eveil', 'JJ'), ('world', 'NN'), ('caused', 'VBD'), ('atheism', 'NN'), ('ridiculous', 'JJ'), ('counterproductive', 'JJ'), ('dialogue', 'NN'), ('newsgroups', 'NNS'), ('see', 'VBP'), ('posts', 'NNS'), ('spirit', 'VBP'), ('condemnation', 'NN'), ('atheists', 'NNS'), ('newsgroup', 'VBP'), ('bacause', 'IN'), ('believe', 'VBP'), ('exactly', 'RB'), ('try', 'VBP'), ('convert', 'JJ'), ('atheists', 'NNS'), ('failing', 'VBG'), ('miserably', 'RB'), ('who', 'WP'), ('wants', 'VBZ'), ('position', 'NN'), ('constantly', 'RB'), ('defending', 'VBG'), ('agaist', 'NN'), ('insulting', 'VBG'), ('attacks', 'NNS'), ('like', 'IN'), ('seem', 'VBP'), ('like', 'IN'), ('sorry', 'NN'), ('blind', 'VBP'), ('get', 'VB'), ('messgae', 'JJ'), ('quote', 'NN'), ('everyone', 'NN'), ('else', 'RB'), ('seemed', 'VBD'), ('tammy', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "posTagged_words=[]\n",
    "for i in range(len(newsgroup_cleaned_tokens)):\n",
    "    posTagged_words.append(nltk.pos_tag(newsgroup_cleaned_tokens[i]))\n",
    "print(\"POS tagging generated for\", len(posTagged_words), \"documents\")\n",
    "print(\"Pos-tagged words for first document are :\\n\",posTagged_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ceating a single tokenized words list\n",
    "\n",
    "Storing all the tokens from every article in a single list \"all_news_tokens\". Printing first 10 words from that list. This list will be used for generating bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 tokes are :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['from',\n",
       " 'healta',\n",
       " 'tammy',\n",
       " 'healy',\n",
       " 'subject',\n",
       " 'judge',\n",
       " 'bobby',\n",
       " 'lines',\n",
       " 'organization',\n",
       " 'walla']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_news_tokens = []\n",
    "for tokens in newsgroup_cleaned_tokens:\n",
    "    for token in tokens:\n",
    "        all_news_tokens.append(token)\n",
    "\n",
    "print(\"First 10 tokes are :\")\n",
    "all_news_tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1-b Finding bigrams\n",
    "\n",
    "It shows the diagram of two adjacent words from tokens. We will be using BigramAssocMeasures from nlt collocations. After that, using BigramCollocationFinder to create biagram finder.\n",
    "\n",
    "Coding reference for all the bigram techniques:\n",
    "* https://medium.com/@nicharuch/collocations-identifying-phrases-that-act-like-individual-words-in-nlp-f58a93a2f84a \n",
    "* Tutorial-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = nltk.collocations.BigramAssocMeasures()\n",
    "bigramFinder = nltk.collocations.BigramCollocationFinder.from_words(all_news_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Frequency with filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(lines, article)</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>(organization, university)</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>(writes, article)</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>(distribution, world)</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>(lines, distribution)</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>(kent, sandvik)</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>(computer, science)</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>(usa, lines)</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>(henry, spencer)</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(would, like)</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>(university, lines)</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>(tin, version)</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>(jon, livesey)</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9731</th>\n",
       "      <td>(does, anyone)</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>(for, example)</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>(livesey, jon)</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>(prb, pat)</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>(computer, graphics)</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(apr, gmt)</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>(state, university)</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          bigram  frequency\n",
       "12              (lines, article)       1088\n",
       "1134  (organization, university)        495\n",
       "1142           (writes, article)        490\n",
       "206        (distribution, world)        371\n",
       "137        (lines, distribution)        316\n",
       "2155             (kent, sandvik)        211\n",
       "1020         (computer, science)        188\n",
       "1944                (usa, lines)        182\n",
       "1951            (henry, spencer)        180\n",
       "27                 (would, like)        179\n",
       "1825         (university, lines)        172\n",
       "4175              (tin, version)        164\n",
       "2288              (jon, livesey)        159\n",
       "9731              (does, anyone)        156\n",
       "2810              (for, example)        151\n",
       "2287              (livesey, jon)        150\n",
       "1929                  (prb, pat)        146\n",
       "4223        (computer, graphics)        141\n",
       "21                    (apr, gmt)        135\n",
       "3048         (state, university)        133"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple bigram using frequency count.\n",
    "# Finding 20 best results using frequency count\n",
    "frequency_bigram = bigramFinder.ngram_fd.items()\n",
    "bigramFrequency = pd.DataFrame(list(frequency_bigram), columns=['bigram','frequency']).sort_values(by='frequency', ascending=False)\n",
    "bigramFrequency.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying POS filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(lines, article)</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(organization, university)</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(writes, article)</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(distribution, world)</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(lines, distribution)</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(kent, sandvik)</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(computer, science)</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(usa, lines)</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(henry, spencer)</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(university, lines)</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(tin, version)</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(jon, livesey)</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(livesey, jon)</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(prb, pat)</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(computer, graphics)</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(apr, gmt)</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(state, university)</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(space, station)</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(anonymous, ftp)</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(institute, technology)</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        bigram  frequency\n",
       "0             (lines, article)       1088\n",
       "1   (organization, university)        495\n",
       "2            (writes, article)        490\n",
       "3        (distribution, world)        371\n",
       "4        (lines, distribution)        316\n",
       "5              (kent, sandvik)        211\n",
       "6          (computer, science)        188\n",
       "7                 (usa, lines)        182\n",
       "8             (henry, spencer)        180\n",
       "9          (university, lines)        172\n",
       "10              (tin, version)        164\n",
       "11              (jon, livesey)        159\n",
       "12              (livesey, jon)        150\n",
       "13                  (prb, pat)        146\n",
       "14        (computer, graphics)        141\n",
       "15                  (apr, gmt)        135\n",
       "16         (state, university)        133\n",
       "17            (space, station)        132\n",
       "18            (anonymous, ftp)        128\n",
       "19     (institute, technology)        125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency bigrams with top 20 results with filter\n",
    "def applyPOSFilter(bigram):\n",
    "    primary_pos_tags = ('JJR', 'JJS', 'JJ', 'NNP', 'NNS', 'NN', 'NNPS')\n",
    "    secondary_pos_tags = ('NNPS', 'NN', 'NNP', 'NNS')\n",
    "    pos_tags = nltk.pos_tag(bigram)\n",
    "    if ((pos_tags[0][1] in primary_pos_tags) and (pos_tags[1][1] in secondary_pos_tags)):\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "#filter bigrams using POS tagging\n",
    "frequency_bigram_filter = bigramFrequency[bigramFrequency.bigram.map(lambda x: applyPOSFilter(x))]\n",
    "frequency_bigram_filter=frequency_bigram_filter.head(20).reset_index().drop(columns=['index'])\n",
    "frequency_bigram_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bigrams using PMI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aam', 'khas'),\n",
       " ('aangeboden', 'binnen'),\n",
       " ('aantal', 'voordrachten'),\n",
       " ('aatdb', 'arabidopsis'),\n",
       " ('abounded', 'intensified'),\n",
       " ('abuser', 'immenant'),\n",
       " ('abusers', 'beltway'),\n",
       " ('accelerating', 'cavities'),\n",
       " ('acedb', 'caenorhabditis'),\n",
       " ('aceitunas', 'alforja'),\n",
       " ('actuator', 'dda'),\n",
       " ('adabas', 'sybase'),\n",
       " ('adders', 'multipliers'),\n",
       " ('addison', 'wesley'),\n",
       " ('admiral', 'hyman'),\n",
       " ('aert', 'jansz'),\n",
       " ('afarensis', 'mya'),\n",
       " ('afd', 'aoct'),\n",
       " ('afgestemd', 'tweedejaars'),\n",
       " ('aforesaid', 'prefixes')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collocation using PMI score\n",
    "bigramFinder.nbest(bigrams.pmi,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(aam, khas)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(pcboard, usr)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(periterr, pericynthion)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(perfecetly, reasoable)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(pentacost, hymn)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(pelletized, ceramic)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(pedro, almodovar)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(peacefully, enjoin)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(patrimony, zorastrian)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(plurbis, unum)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(passel, sterile)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(particularities, aam)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(partake, joyously)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(paronoid, moromn)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(parabola, queasiness)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(overige, sprekers)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(permannet, ftsc)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(perplexed, thereabout)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(persecutions, abounded)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(pert, gant)</td>\n",
       "      <td>19.04229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bigram       PMI\n",
       "0                (aam, khas)  19.04229\n",
       "1             (pcboard, usr)  19.04229\n",
       "2   (periterr, pericynthion)  19.04229\n",
       "3    (perfecetly, reasoable)  19.04229\n",
       "4          (pentacost, hymn)  19.04229\n",
       "5      (pelletized, ceramic)  19.04229\n",
       "6         (pedro, almodovar)  19.04229\n",
       "7       (peacefully, enjoin)  19.04229\n",
       "8    (patrimony, zorastrian)  19.04229\n",
       "9            (plurbis, unum)  19.04229\n",
       "10         (passel, sterile)  19.04229\n",
       "11    (particularities, aam)  19.04229\n",
       "12       (partake, joyously)  19.04229\n",
       "13        (paronoid, moromn)  19.04229\n",
       "14    (parabola, queasiness)  19.04229\n",
       "15       (overige, sprekers)  19.04229\n",
       "16         (permannet, ftsc)  19.04229\n",
       "17   (perplexed, thereabout)  19.04229\n",
       "18  (persecutions, abounded)  19.04229\n",
       "19              (pert, gant)  19.04229"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collocation using PMI score\n",
    "bigramPMITable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.pmi)), columns=['bigram','PMI']).sort_values(by='PMI', ascending=False)\n",
    "bigramPMITable=bigramPMITable.head(20).reset_index().drop(columns=['index'])\n",
    "bigramPMITable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bigrams using T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lines', 'article'),\n",
       " ('organization', 'university'),\n",
       " ('writes', 'article'),\n",
       " ('distribution', 'world'),\n",
       " ('lines', 'distribution'),\n",
       " ('kent', 'sandvik'),\n",
       " ('computer', 'science'),\n",
       " ('henry', 'spencer'),\n",
       " ('usa', 'lines'),\n",
       " ('tin', 'version'),\n",
       " ('jon', 'livesey'),\n",
       " ('would', 'like'),\n",
       " ('does', 'anyone'),\n",
       " ('university', 'lines'),\n",
       " ('livesey', 'jon'),\n",
       " ('for', 'example'),\n",
       " ('prb', 'pat'),\n",
       " ('computer', 'graphics'),\n",
       " ('apr', 'gmt'),\n",
       " ('state', 'university')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramFinder.nbest(bigrams.student_t,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>T-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(lines, article)</td>\n",
       "      <td>32.531515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(organization, university)</td>\n",
       "      <td>21.792828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(writes, article)</td>\n",
       "      <td>21.621953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(distribution, world)</td>\n",
       "      <td>19.191999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(lines, distribution)</td>\n",
       "      <td>17.501842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(kent, sandvik)</td>\n",
       "      <td>14.514741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(computer, science)</td>\n",
       "      <td>13.641671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(henry, spencer)</td>\n",
       "      <td>13.404664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(usa, lines)</td>\n",
       "      <td>13.314280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(tin, version)</td>\n",
       "      <td>12.786509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(jon, livesey)</td>\n",
       "      <td>12.596347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(would, like)</td>\n",
       "      <td>12.587358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(does, anyone)</td>\n",
       "      <td>12.454849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(university, lines)</td>\n",
       "      <td>12.299323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(livesey, jon)</td>\n",
       "      <td>12.233887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(for, example)</td>\n",
       "      <td>12.228209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(prb, pat)</td>\n",
       "      <td>12.076009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(computer, graphics)</td>\n",
       "      <td>11.786374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(apr, gmt)</td>\n",
       "      <td>11.610912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(state, university)</td>\n",
       "      <td>11.440077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        bigram    T-score\n",
       "0             (lines, article)  32.531515\n",
       "1   (organization, university)  21.792828\n",
       "2            (writes, article)  21.621953\n",
       "3        (distribution, world)  19.191999\n",
       "4        (lines, distribution)  17.501842\n",
       "5              (kent, sandvik)  14.514741\n",
       "6          (computer, science)  13.641671\n",
       "7             (henry, spencer)  13.404664\n",
       "8                 (usa, lines)  13.314280\n",
       "9               (tin, version)  12.786509\n",
       "10              (jon, livesey)  12.596347\n",
       "11               (would, like)  12.587358\n",
       "12              (does, anyone)  12.454849\n",
       "13         (university, lines)  12.299323\n",
       "14              (livesey, jon)  12.233887\n",
       "15              (for, example)  12.228209\n",
       "16                  (prb, pat)  12.076009\n",
       "17        (computer, graphics)  11.786374\n",
       "18                  (apr, gmt)  11.610912\n",
       "19         (state, university)  11.440077"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  bigrams with T-test (top 20 values)\n",
    "bigramTTesttable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.student_t)), columns=['bigram','T-score']).sort_values(by='T-score', ascending=False)\n",
    "bigramTTesttable.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying POS filter in T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>T-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(lines, article)</td>\n",
       "      <td>32.531515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(organization, university)</td>\n",
       "      <td>21.792828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(writes, article)</td>\n",
       "      <td>21.621953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(distribution, world)</td>\n",
       "      <td>19.191999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(lines, distribution)</td>\n",
       "      <td>17.501842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(kent, sandvik)</td>\n",
       "      <td>14.514741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(computer, science)</td>\n",
       "      <td>13.641671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(henry, spencer)</td>\n",
       "      <td>13.404664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(usa, lines)</td>\n",
       "      <td>13.314280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(tin, version)</td>\n",
       "      <td>12.786509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(jon, livesey)</td>\n",
       "      <td>12.596347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(university, lines)</td>\n",
       "      <td>12.299323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(livesey, jon)</td>\n",
       "      <td>12.233887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(prb, pat)</td>\n",
       "      <td>12.076009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(computer, graphics)</td>\n",
       "      <td>11.786374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(apr, gmt)</td>\n",
       "      <td>11.610912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(state, university)</td>\n",
       "      <td>11.440077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(space, station)</td>\n",
       "      <td>11.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(anonymous, ftp)</td>\n",
       "      <td>11.302758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(institute, technology)</td>\n",
       "      <td>11.162339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        bigram    T-score\n",
       "0             (lines, article)  32.531515\n",
       "1   (organization, university)  21.792828\n",
       "2            (writes, article)  21.621953\n",
       "3        (distribution, world)  19.191999\n",
       "4        (lines, distribution)  17.501842\n",
       "5              (kent, sandvik)  14.514741\n",
       "6          (computer, science)  13.641671\n",
       "7             (henry, spencer)  13.404664\n",
       "8                 (usa, lines)  13.314280\n",
       "9               (tin, version)  12.786509\n",
       "10              (jon, livesey)  12.596347\n",
       "11         (university, lines)  12.299323\n",
       "12              (livesey, jon)  12.233887\n",
       "13                  (prb, pat)  12.076009\n",
       "14        (computer, graphics)  11.786374\n",
       "15                  (apr, gmt)  11.610912\n",
       "16         (state, university)  11.440077\n",
       "17            (space, station)  11.411700\n",
       "18            (anonymous, ftp)  11.302758\n",
       "19     (institute, technology)  11.162339"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying pos filter in T-test\n",
    "filtered_TTest_bigrams = bigramTTesttable[bigramTTesttable.bigram.map(lambda x: applyPOSFilter(x))]\n",
    "filtered_TTest_bigrams=filtered_TTest_bigrams.head(20).reset_index().drop(columns=['index'])\n",
    "filtered_TTest_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bigrams using Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aaaa', 'bbbb'),\n",
       " ('aam', 'khas'),\n",
       " ('aangeboden', 'binnen'),\n",
       " ('aantal', 'voordrachten'),\n",
       " ('aatdb', 'arabidopsis'),\n",
       " ('aawin', 'aaplay'),\n",
       " ('abg', 'fubbg'),\n",
       " ('abounded', 'intensified'),\n",
       " ('abpsoft', 'mehl'),\n",
       " ('abuser', 'immenant'),\n",
       " ('abusers', 'beltway'),\n",
       " ('accelerating', 'cavities'),\n",
       " ('acedb', 'caenorhabditis'),\n",
       " ('aceitunas', 'alforja'),\n",
       " ('actuator', 'dda'),\n",
       " ('adabas', 'sybase'),\n",
       " ('adage', 'ikonas'),\n",
       " ('adders', 'multipliers'),\n",
       " ('addison', 'wesley'),\n",
       " ('admiral', 'hyman')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramFinder.nbest(bigrams.chi_sq,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>chi-square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(aaaa, bbbb)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(pacman, visicalc)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(patrimony, zorastrian)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(passel, sterile)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(particularities, aam)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(partake, joyously)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(paronoid, moromn)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(parke, fascia)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(parabola, queasiness)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(pankaj, oberoi)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(padmini, srivathsa)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(overige, sprekers)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(pcboard, usr)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(overbearing, totalitarianists)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(outskirts, bumping)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(outcasts, mainline)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(othe, optimisations)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(otc, plt)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(ostanes, hystaspes)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(osman, basbugoglu)</td>\n",
       "      <td>539884.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             bigram  chi-square\n",
       "0                      (aaaa, bbbb)    539884.0\n",
       "1                (pacman, visicalc)    539884.0\n",
       "2           (patrimony, zorastrian)    539884.0\n",
       "3                 (passel, sterile)    539884.0\n",
       "4            (particularities, aam)    539884.0\n",
       "5               (partake, joyously)    539884.0\n",
       "6                (paronoid, moromn)    539884.0\n",
       "7                   (parke, fascia)    539884.0\n",
       "8            (parabola, queasiness)    539884.0\n",
       "9                  (pankaj, oberoi)    539884.0\n",
       "10             (padmini, srivathsa)    539884.0\n",
       "11              (overige, sprekers)    539884.0\n",
       "12                   (pcboard, usr)    539884.0\n",
       "13  (overbearing, totalitarianists)    539884.0\n",
       "14             (outskirts, bumping)    539884.0\n",
       "15             (outcasts, mainline)    539884.0\n",
       "16            (othe, optimisations)    539884.0\n",
       "17                       (otc, plt)    539884.0\n",
       "18             (ostanes, hystaspes)    539884.0\n",
       "19              (osman, basbugoglu)    539884.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigrams with chi-square \n",
    "bigramChiTable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.chi_sq)), columns=['bigram','chi-square']).sort_values(by='chi-square', ascending=False)\n",
    "bigramChiTable=bigramChiTable.head(20).reset_index().drop(columns=['index'])\n",
    "bigramChiTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1-c Overlap among the techniques\n",
    "\n",
    "As shown in the table below, \"Frequency with Filter\" and \"T-test with Filter\" techniques have almost same results. The most 2 adjacent words are \"lines\" and \"article\" according to this result. Apart from this, results of \"PMI\" and \"Chi-Square Test\" are also similar. However, results of \"Frequency with Filter\" and \"T-test with Filter\" are not at all matching with the results of \"PMI\" and \"Chi-Square Test\" techniques.\n",
    "\n",
    "\n",
    "#### Combining the results\n",
    "\n",
    "It makes sense to combine results obtained from multiple techniques. For example, \"Frequency with Filter\" and \"T-test with Filter\" have almost similar results, so if we combine both the results, we can get more insights on the result, as the bigrams which are produced by both the models will have less chance of error. Also, if we combine both the results of PMI and Frequency with filter and we can take advantage of both probability lift and frequency of occurrence.\n",
    "\n",
    "Reference: https://medium.com/@nicharuch/collocations-identifying-phrases-that-act-like-individual-words-in-nlp-f58a93a2f84a\n",
    "\n",
    "\n",
    "### Comparing all the bigram techniques top 20 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency with Filter</th>\n",
       "      <th>PMI</th>\n",
       "      <th>T-test with Filter</th>\n",
       "      <th>Chi-Square Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(lines, article)</td>\n",
       "      <td>(aam, khas)</td>\n",
       "      <td>(lines, article)</td>\n",
       "      <td>(aaaa, bbbb)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(organization, university)</td>\n",
       "      <td>(pcboard, usr)</td>\n",
       "      <td>(organization, university)</td>\n",
       "      <td>(pacman, visicalc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(writes, article)</td>\n",
       "      <td>(periterr, pericynthion)</td>\n",
       "      <td>(writes, article)</td>\n",
       "      <td>(patrimony, zorastrian)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(distribution, world)</td>\n",
       "      <td>(perfecetly, reasoable)</td>\n",
       "      <td>(distribution, world)</td>\n",
       "      <td>(passel, sterile)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(lines, distribution)</td>\n",
       "      <td>(pentacost, hymn)</td>\n",
       "      <td>(lines, distribution)</td>\n",
       "      <td>(particularities, aam)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(kent, sandvik)</td>\n",
       "      <td>(pelletized, ceramic)</td>\n",
       "      <td>(kent, sandvik)</td>\n",
       "      <td>(partake, joyously)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(computer, science)</td>\n",
       "      <td>(pedro, almodovar)</td>\n",
       "      <td>(computer, science)</td>\n",
       "      <td>(paronoid, moromn)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(usa, lines)</td>\n",
       "      <td>(peacefully, enjoin)</td>\n",
       "      <td>(henry, spencer)</td>\n",
       "      <td>(parke, fascia)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(henry, spencer)</td>\n",
       "      <td>(patrimony, zorastrian)</td>\n",
       "      <td>(usa, lines)</td>\n",
       "      <td>(parabola, queasiness)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(university, lines)</td>\n",
       "      <td>(plurbis, unum)</td>\n",
       "      <td>(tin, version)</td>\n",
       "      <td>(pankaj, oberoi)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(tin, version)</td>\n",
       "      <td>(passel, sterile)</td>\n",
       "      <td>(jon, livesey)</td>\n",
       "      <td>(padmini, srivathsa)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(jon, livesey)</td>\n",
       "      <td>(particularities, aam)</td>\n",
       "      <td>(university, lines)</td>\n",
       "      <td>(overige, sprekers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(livesey, jon)</td>\n",
       "      <td>(partake, joyously)</td>\n",
       "      <td>(livesey, jon)</td>\n",
       "      <td>(pcboard, usr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(prb, pat)</td>\n",
       "      <td>(paronoid, moromn)</td>\n",
       "      <td>(prb, pat)</td>\n",
       "      <td>(overbearing, totalitarianists)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(computer, graphics)</td>\n",
       "      <td>(parabola, queasiness)</td>\n",
       "      <td>(computer, graphics)</td>\n",
       "      <td>(outskirts, bumping)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(apr, gmt)</td>\n",
       "      <td>(overige, sprekers)</td>\n",
       "      <td>(apr, gmt)</td>\n",
       "      <td>(outcasts, mainline)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(state, university)</td>\n",
       "      <td>(permannet, ftsc)</td>\n",
       "      <td>(state, university)</td>\n",
       "      <td>(othe, optimisations)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(space, station)</td>\n",
       "      <td>(perplexed, thereabout)</td>\n",
       "      <td>(space, station)</td>\n",
       "      <td>(otc, plt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(anonymous, ftp)</td>\n",
       "      <td>(persecutions, abounded)</td>\n",
       "      <td>(anonymous, ftp)</td>\n",
       "      <td>(ostanes, hystaspes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(institute, technology)</td>\n",
       "      <td>(pert, gant)</td>\n",
       "      <td>(institute, technology)</td>\n",
       "      <td>(osman, basbugoglu)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Frequency with Filter                       PMI  \\\n",
       "0             (lines, article)               (aam, khas)   \n",
       "1   (organization, university)            (pcboard, usr)   \n",
       "2            (writes, article)  (periterr, pericynthion)   \n",
       "3        (distribution, world)   (perfecetly, reasoable)   \n",
       "4        (lines, distribution)         (pentacost, hymn)   \n",
       "5              (kent, sandvik)     (pelletized, ceramic)   \n",
       "6          (computer, science)        (pedro, almodovar)   \n",
       "7                 (usa, lines)      (peacefully, enjoin)   \n",
       "8             (henry, spencer)   (patrimony, zorastrian)   \n",
       "9          (university, lines)           (plurbis, unum)   \n",
       "10              (tin, version)         (passel, sterile)   \n",
       "11              (jon, livesey)    (particularities, aam)   \n",
       "12              (livesey, jon)       (partake, joyously)   \n",
       "13                  (prb, pat)        (paronoid, moromn)   \n",
       "14        (computer, graphics)    (parabola, queasiness)   \n",
       "15                  (apr, gmt)       (overige, sprekers)   \n",
       "16         (state, university)         (permannet, ftsc)   \n",
       "17            (space, station)   (perplexed, thereabout)   \n",
       "18            (anonymous, ftp)  (persecutions, abounded)   \n",
       "19     (institute, technology)              (pert, gant)   \n",
       "\n",
       "            T-test with Filter                  Chi-Square Test  \n",
       "0             (lines, article)                     (aaaa, bbbb)  \n",
       "1   (organization, university)               (pacman, visicalc)  \n",
       "2            (writes, article)          (patrimony, zorastrian)  \n",
       "3        (distribution, world)                (passel, sterile)  \n",
       "4        (lines, distribution)           (particularities, aam)  \n",
       "5              (kent, sandvik)              (partake, joyously)  \n",
       "6          (computer, science)               (paronoid, moromn)  \n",
       "7             (henry, spencer)                  (parke, fascia)  \n",
       "8                 (usa, lines)           (parabola, queasiness)  \n",
       "9               (tin, version)                 (pankaj, oberoi)  \n",
       "10              (jon, livesey)             (padmini, srivathsa)  \n",
       "11         (university, lines)              (overige, sprekers)  \n",
       "12              (livesey, jon)                   (pcboard, usr)  \n",
       "13                  (prb, pat)  (overbearing, totalitarianists)  \n",
       "14        (computer, graphics)             (outskirts, bumping)  \n",
       "15                  (apr, gmt)             (outcasts, mainline)  \n",
       "16         (state, university)            (othe, optimisations)  \n",
       "17            (space, station)                       (otc, plt)  \n",
       "18            (anonymous, ftp)             (ostanes, hystaspes)  \n",
       "19     (institute, technology)              (osman, basbugoglu)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_comparison = pd.concat([frequency_bigram_filter['bigram'], bigramPMITable['bigram'], filtered_TTest_bigrams['bigram'], bigramChiTable['bigram']],axis=1)\n",
    "bigrams_comparison.columns = ['Frequency with Filter', 'PMI', 'T-test with Filter', 'Chi-Square Test']\n",
    "bigrams_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. SVM and Naive Bayes for Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2-a Cleaning the dataset\n",
    "\n",
    "For cleaning the dataset we have followed 3 steps:\n",
    "1. Remove stop words\n",
    "2. Remove numbers and other non-letter characters\n",
    "3. Stem the words\n",
    "\n",
    "We have tokenized each news article into words using \"word_tokenize\" method from nltk library. \"tokens_words_for_newsgroups\" list will contain the words for each document. After that, for cleaning the dataset, we have removed stopwords, non-alphabetic characters and numbers. Moreover, we have also removed numbers. Thereafter, we have performed stemming on the words. For example, \"Game\" and \"Gaming\" represents the same word, so it can be considered as the single word. For stemming, we have user PorterStemmer from nltk library. After that, we have converted the stemmed word into sentences.\n",
    "\n",
    "All the 3 steps are shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenize the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387\n",
      "['From', ':', 'healta', '@', 'saturn.wwc.edu', '(', 'Tammy', 'R', 'Healy', ')', 'Subject', ':', 'Re', ':', 'who', 'are', 'we', 'to', 'judge', ',', 'Bobby', '?', 'Lines', ':', '38', 'Organization', ':', 'Walla', 'Walla', 'College', 'Lines', ':', '38', 'In', 'article', '<', '1993Apr14.213356.22176', '@', 'ultb.isc.rit.edu', '>', 'snm6394', '@', 'ultb.isc.rit.edu', '(', 'S.N', '.', 'Mozumder', ')', 'writes', ':', '>', 'From', ':', 'snm6394', '@', 'ultb.isc.rit.edu', '(', 'S.N', '.', 'Mozumder', ')', '>', 'Subject', ':', 'Re', ':', 'who', 'are', 'we', 'to', 'judge', ',', 'Bobby', '?', '>', 'Date', ':', 'Wed', ',', '14', 'Apr', '1993', '21:33:56', 'GMT', '>', 'In', 'article', '<', 'healta.56.734556346', '@', 'saturn.wwc.edu', '>', 'healta', '@', 'saturn.wwc.edu', '(', 'TAMMY', 'R', 'HEALY', ')', 'writes', ':', '>', '>', 'Bobby', ',', '>', '>', '>', '>', 'I', 'would', 'like', 'to', 'take', 'the', 'liberty', 'to', 'quote', 'from', 'a', 'Christian', 'writer', 'named', '>', '>', 'Ellen', 'G.', 'White', '.', 'I', 'hope', 'that', 'what', 'she', 'said', 'will', 'help', 'you', 'to', 'edit', 'your', '>', '>', 'remarks', 'in', 'this', 'group', 'in', 'the', 'future', '.', '>', '>', '>', '>', \"''\", 'Do', 'not', 'set', 'yourself', 'as', 'a', 'standard', '.', 'Do', 'not', 'make', 'your', 'opinions', ',', 'your', 'views', '>', '>', 'of', 'duty', ',', 'your', 'interpretations', 'of', 'scripture', ',', 'a', 'criterion', 'for', 'others', 'and', 'in', '>', '>', 'your', 'heart', 'condemn', 'them', 'if', 'they', 'do', 'not', 'come', 'up', 'to', 'your', 'ideal', '.', \"''\", '>', '>', 'Thoughts', 'Fromthe', 'Mount', 'of', 'Blessing', 'p.', '124', '>', '>', '>', '>', 'I', 'hope', 'quoting', 'this', 'does', \"n't\", 'make', 'the', 'atheists', 'gag', ',', 'but', 'I', 'think', 'Ellen', 'White', '>', '>', 'put', 'it', 'better', 'than', 'I', 'could', '.', '>', '>', '>', '>', 'Tammy', '>', '>', 'Point', '?', '>', '>', 'Peace', ',', '>', '>', 'Bobby', 'Mozumder', '>', 'My', 'point', 'is', 'that', 'you', 'set', 'up', 'your', 'views', 'as', 'the', 'only', 'way', 'to', 'believe', '.', 'Saying', 'that', 'all', 'eveil', 'in', 'this', 'world', 'is', 'caused', 'by', 'atheism', 'is', 'ridiculous', 'and', 'counterproductive', 'to', 'dialogue', 'in', 'this', 'newsgroups', '.', 'I', 'see', 'in', 'your', 'posts', 'a', 'spirit', 'of', 'condemnation', 'of', 'the', 'atheists', 'in', 'this', 'newsgroup', 'bacause', 'they', \"don'\", 't', 'believe', 'exactly', 'as', 'you', 'do', '.', 'If', 'you', \"'re\", 'here', 'to', 'try', 'to', 'convert', 'the', 'atheists', 'here', ',', 'you', \"'re\", 'failing', 'miserably', '.', 'Who', 'wants', 'to', 'be', 'in', 'position', 'of', 'constantly', 'defending', 'themselves', 'agaist', 'insulting', 'attacks', ',', 'like', 'you', 'seem', 'to', 'like', 'to', 'do', '?', '!', 'I', \"'m\", 'sorry', 'you', \"'re\", 'so', 'blind', 'that', 'you', 'did', \"n't\", 'get', 'the', 'messgae', 'in', 'the', 'quote', ',', 'everyone', 'else', 'has', 'seemed', 'to', '.', 'Tammy']\n"
     ]
    }
   ],
   "source": [
    "# tokenize each newsgroup into words\n",
    "tokens_words_for_newsgroups=[]\n",
    "for i in range(len(newsgroups_data.data)):\n",
    "    tokens_words_for_newsgroups.append(word_tokenize(newsgroups_data.data[i]))\n",
    "\n",
    "# printing tokens of first news article\n",
    "print(len(tokens_words_for_newsgroups))\n",
    "print(tokens_words_for_newsgroups[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Removing stop-words, numbers and non-alphabetic characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387\n",
      "Cleaned tokens:\n",
      "\n",
      " ['healta', 'tammy', 'r', 'healy', 'subject', 'judge', 'bobby', 'lines', 'organization', 'walla', 'walla', 'college', 'lines', 'article', 'mozumder', 'writes', 'mozumder', 'subject', 'judge', 'bobby', 'date', 'wed', 'apr', 'gmt', 'article', 'healta', 'tammy', 'r', 'healy', 'writes', 'bobby', 'would', 'like', 'take', 'liberty', 'quote', 'christian', 'writer', 'named', 'ellen', 'white', 'hope', 'said', 'help', 'edit', 'remarks', 'group', 'future', 'set', 'standard', 'make', 'opinions', 'views', 'duty', 'interpretations', 'scripture', 'criterion', 'others', 'heart', 'condemn', 'come', 'ideal', 'thoughts', 'fromthe', 'mount', 'blessing', 'hope', 'quoting', 'make', 'atheists', 'gag', 'think', 'ellen', 'white', 'put', 'better', 'could', 'tammy', 'point', 'peace', 'bobby', 'mozumder', 'point', 'set', 'views', 'way', 'believe', 'saying', 'eveil', 'world', 'caused', 'atheism', 'ridiculous', 'counterproductive', 'dialogue', 'newsgroups', 'see', 'posts', 'spirit', 'condemnation', 'atheists', 'newsgroup', 'bacause', 'believe', 'exactly', 'try', 'convert', 'atheists', 'failing', 'miserably', 'wants', 'position', 'constantly', 'defending', 'agaist', 'insulting', 'attacks', 'like', 'seem', 'like', 'sorry', 'blind', 'get', 'messgae', 'quote', 'everyone', 'else', 'seemed', 'tammy']\n"
     ]
    }
   ],
   "source": [
    "# Removing stopwords, number and other non-letter characters\n",
    "newsGroup_filtered_tokens=[]\n",
    "stop_words_english =set(stopwords.words(\"english\"))\n",
    "\n",
    "for i in range(len(tokens_words_for_newsgroups)):\n",
    "    temp=[]\n",
    "    for w in tokens_words_for_newsgroups[i]:\n",
    "        w=w.lower()\n",
    "        if ((w not in stop_words_english) and w.isalpha()):\n",
    "            temp.append(w.lower())\n",
    "    newsGroup_filtered_tokens.append(temp)\n",
    "\n",
    "# Printing cleaned tokens of first news article\n",
    "print(len(newsGroup_filtered_tokens))\n",
    "print(\"Cleaned tokens:\\n\\n\",newsGroup_filtered_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stemming the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed tokens\n",
      "\n",
      " ['healta', 'tammi', 'r', 'heali', 'subject', 'judg', 'bobbi', 'line', 'organ', 'walla', 'walla', 'colleg', 'line', 'articl', 'mozumd', 'write', 'mozumd', 'subject', 'judg', 'bobbi', 'date', 'wed', 'apr', 'gmt', 'articl', 'healta', 'tammi', 'r', 'heali', 'write', 'bobbi', 'would', 'like', 'take', 'liberti', 'quot', 'christian', 'writer', 'name', 'ellen', 'white', 'hope', 'said', 'help', 'edit', 'remark', 'group', 'futur', 'set', 'standard', 'make', 'opinion', 'view', 'duti', 'interpret', 'scriptur', 'criterion', 'other', 'heart', 'condemn', 'come', 'ideal', 'thought', 'fromth', 'mount', 'bless', 'hope', 'quot', 'make', 'atheist', 'gag', 'think', 'ellen', 'white', 'put', 'better', 'could', 'tammi', 'point', 'peac', 'bobbi', 'mozumd', 'point', 'set', 'view', 'way', 'believ', 'say', 'eveil', 'world', 'caus', 'atheism', 'ridicul', 'counterproduct', 'dialogu', 'newsgroup', 'see', 'post', 'spirit', 'condemn', 'atheist', 'newsgroup', 'bacaus', 'believ', 'exactli', 'tri', 'convert', 'atheist', 'fail', 'miser', 'want', 'posit', 'constantli', 'defend', 'agaist', 'insult', 'attack', 'like', 'seem', 'like', 'sorri', 'blind', 'get', 'messga', 'quot', 'everyon', 'els', 'seem', 'tammi']\n"
     ]
    }
   ],
   "source": [
    "# stemming the tokens\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "stemmed_news_group=[]\n",
    "\n",
    "for i in range(len(newsGroup_filtered_tokens)):\n",
    "    temp=[]\n",
    "    for w in newsGroup_filtered_tokens[i]:\n",
    "        temp.append(ps.stem(w))\n",
    "    stemmed_news_group.append(temp)\n",
    "        \n",
    "print(\"Stemmed tokens\\n\\n\",stemmed_news_group[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healta tammi r heali subject judg bobbi line organ walla walla colleg line articl mozumd write mozumd subject judg bobbi date wed apr gmt articl healta tammi r heali write bobbi would like take liberti quot christian writer name ellen white hope said help edit remark group futur set standard make opinion view duti interpret scriptur criterion other heart condemn come ideal thought fromth mount bless hope quot make atheist gag think ellen white put better could tammi point peac bobbi mozumd point set view way believ say eveil world caus atheism ridicul counterproduct dialogu newsgroup see post spirit condemn atheist newsgroup bacaus believ exactli tri convert atheist fail miser want posit constantli defend agaist insult attack like seem like sorri blind get messga quot everyon els seem tammi\n"
     ]
    }
   ],
   "source": [
    "# coverting stemmed tokens into sentences\n",
    "for i in range(len(stemmed_news_group)):\n",
    "    stemmed_news_group[i]=\" \".join(stemmed_news_group[i])\n",
    "\n",
    "print(stemmed_news_group[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2-b Bag-of-words and tf-idf vector representation\n",
    "\n",
    "### Bag-of-words representation\n",
    "\n",
    "It is a way of representing the text data in Data Science. The problem with text data is that it can be completely random and very messy. However, Machine Learning algorithms expects the data to be in some formatted way. Hence, we can use bag-of-words representation for arranging the text data. It is a way in which features are extracted from the text data. This technique involves a list of known words and a measure on how to find the presence of these words. In the bag-of-words technique, the structure of words/sentences is not retained. Now, two documents are considered similar based on their similarity of bag-of-words.\n",
    "\n",
    "In our example, we will be using \"fit_transform\" method of \"CountVectorizer\" from scikit learn library. For our dataset, we have printed the bag-of-words shape and it shows that there are 23017 words in all of the documents.\n",
    "\n",
    "Reference: https://machinelearningmastery.com/gentle-introduction-bag-words-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3387, 23107)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bag of words representation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "bagOfWords= count_vect.fit_transform(stemmed_news_group)\n",
    "bagOfWords.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF weighted vector representation\n",
    "\n",
    "TF-IDF is acronym for Term Frequency-Inverse Document Frequency. It is a way in which text data can be represented in meaningful way. It will represent the frequency of words in the document. DF represents the number of total documents in the dataset. Now, if the words occurs in many documents, then its weight should be less. Because, if the word is in multiple documents, then it will not a major role in deciding the similarities between 2 documents. In our case, we are using \"fit_transform\" method from TfidfTransformer given in scikit learn library. We are supplying above generated bag-words to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3387, 23107)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating tf-idf vector\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf = tfidf_transformer.fit_transform(bagOfWords)\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import  precision_score, recall_score,f1_score,accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2-c Applying SVM and Multinomial NB\n",
    "\n",
    "### Splitting the dataset\n",
    "\n",
    "We have splitted out the dataset into 2 parts:\n",
    "1. Training set- 70%\n",
    "2. Testing set- 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2370, 23107)\n",
      "(2370,)\n",
      "(1017, 23107)\n",
      "(1017,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf, newsgroups_data.target, test_size=0.30,random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "y_train=y_train.reshape((y_train.shape[0],1))\n",
    "y_test=y_test.reshape((y_test.shape[0],1))\n",
    "evaluation=[0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Multinomial NB\n",
    "\n",
    "We are providing X_train and Y_train to the MultinomilaNB and training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shrey amin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "NB_clf = MultinomialNB().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate MultinomialNB classifier\n",
    "\n",
    "For evaluating the performance of classifier we have created a common function `evaluateClassifier(classifier,model,index)` which will accept the classifier, the model name and index, and the function will return the predicted value for Y.\n",
    "\n",
    "In case of multinomial NB, we have received following results:\n",
    "- Training Accuracy : 94% (Approximately)\n",
    "- Test Accuracy : 91% (Approximately)\n",
    "- Precision : 92% (Approximately)\n",
    "- Recall : 91% (Approximately)\n",
    "\n",
    "As it can be seen, multinomial NB has training accuracy of 94%, which is considered a really good model. Also, on the testing dataset we have received approximately 91% accuracy, which indicates our model is not over-fitting in this case. Apart from these evaluation matrices, we have received approximately 92% precision and approximately 91% recall for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: Lab-2\n",
    "def evaluateClassifier(classifier,model,index):\n",
    "    print(\"Performance of \"+model)\n",
    "    y_predicted=classifier.predict(X_test)\n",
    "    x_predicted=classifier.predict(X_train)\n",
    "    evaluation[index]=accuracy_score(y_test, y_predicted)\n",
    "    print(\"\\nTraining accuracy score: %1.3f\"%accuracy_score(y_train, x_predicted))\n",
    "    print( \"Test accuracy_score:%1.3f\"%accuracy_score(y_test, y_predicted) )\n",
    "    print(\"Precision: %1.3f\" % precision_score(y_test, y_predicted,average='weighted'))\n",
    "    print(\"Recall: %1.3f\" % recall_score(y_test, y_predicted,average='weighted'))\n",
    "    print(\"F1: %1.3f\\n\" % f1_score(y_test, y_predicted,average='weighted'))\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of MultinomialNB classifier\n",
      "\n",
      "Training accuracy score: 0.944\n",
      "Test accuracy_score:0.908\n",
      "Precision: 0.922\n",
      "Recall: 0.908\n",
      "F1: 0.902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_multinomialNB=evaluateClassifier(classifier=NB_clf,model=\"MultinomialNB classifier\",index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeShape(predictedList):\n",
    "    y_predicted=[]\n",
    "    temp=[]\n",
    "    for y in predictedList:\n",
    "        temp.append(y)\n",
    "        y_predicted.append(temp)\n",
    "        temp=[]\n",
    "    y_predicted=np.array(y_predicted)\n",
    "    return y_predicted\n",
    "y_predicted_multinomialNB=changeShape(y_predicted_multinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix of MultinomialNB\n",
    "\n",
    "Confusion matrix for MultinomialNB is shown in the below table. As it can be seen from the table, that the model has very high accuracy except for the category \"sci.space\". We can say that there is a confusion between \"sci.space\" and \"alt.atheism\" categories. During our testing we have recieved 63 instances which are predicted \"alt.atheism\", but it were actually predicted as \"sci.space\". Except this scenario, multinomial NB has a very good accuracy for all the other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(model,y_predicted):\n",
    "    print(\"Confusion matrix of \"+model)\n",
    "    cm=pd.DataFrame(confusion_matrix(y_test, y_predicted))\n",
    "    cm.columns=['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "    cm.index=['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of MultinomialNB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.space</th>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    alt.atheism  talk.religion.misc  comp.graphics  sci.space\n",
       "alt.atheism                 221                   0              2          1\n",
       "talk.religion.misc            0                 294              3          0\n",
       "comp.graphics                 3                   7            297          0\n",
       "sci.space                    63                   5             10        111"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatrix(\"MultinomialNB\",y_predicted_multinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM\n",
    "\n",
    "We have trained SVM with following kernels:\n",
    "\n",
    "1. Linear\n",
    "2. RBF\n",
    "3. Poly\n",
    "4. Sigmoid\n",
    "\n",
    "We have created a common function `svmClassifier(kernel)`, which accepts the kernel and implements the SVM classifier on it. Following are the performance metrices we have received for each kernel:\n",
    "\n",
    "#### Linear\n",
    "- Training Accuracy : 99% (Approximately)\n",
    "- Test Accuracy : 95% (Approximately)\n",
    "- Precision : 96% (Approximately)\n",
    "- Recall : 96% (Approximately)\n",
    "\n",
    "#### RBF\n",
    "- Training Accuracy : 29% (Approximately)\n",
    "- Test Accuracy : 30% (Approximately)\n",
    "- Precision : 9% (Approximately)\n",
    "- Recall : 30% (Approximately)\n",
    "\n",
    "#### Poly\n",
    "- Training Accuracy : 29% (Approximately)\n",
    "- Test Accuracy : 30% (Approximately)\n",
    "- Precision : 9% (Approximately)\n",
    "- Recall : 30% (Approximately)\n",
    "\n",
    "#### Sigmoid\n",
    "- Training Accuracy : 29% (Approximately)\n",
    "- Test Accuracy : 30% (Approximately)\n",
    "- Precision : 9% (Approximately)\n",
    "- Recall : 30% (Approximately)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the kernel to train Support Vector Machine (SVM)\n",
    "\n",
    "As it can be seen in the above results, changing the kernel of SVM has a very huge impact on its performance. Linear SVM has approxmiately 95% accurancy. However, all other kernels for SVM has only 30% accuracy. Thus, Linear SVM tends to perform better than other kernel.\n",
    "\n",
    "Reference: https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shrey amin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Support vector machine classifier with linear kernel \n",
      "\n",
      "Training accuracy score: 0.995\n",
      "Test accuracy_score:0.956\n",
      "Precision: 0.956\n",
      "Recall: 0.956\n",
      "F1: 0.956\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shrey amin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Support vector machine classifier with RBF kernel \n",
      "\n",
      "Training accuracy score: 0.287\n",
      "Test accuracy_score:0.302\n",
      "Precision: 0.091\n",
      "Recall: 0.302\n",
      "F1: 0.140\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shrey amin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\shrey amin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Support vector machine classifier with polynomial kernel \n",
      "\n",
      "Training accuracy score: 0.287\n",
      "Test accuracy_score:0.302\n",
      "Precision: 0.091\n",
      "Recall: 0.302\n",
      "F1: 0.140\n",
      "\n",
      "Performance of Support vector machine classifier with sigmoid kernel \n",
      "\n",
      "Training accuracy score: 0.287\n",
      "Test accuracy_score:0.302\n",
      "Precision: 0.091\n",
      "Recall: 0.302\n",
      "F1: 0.140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training the SVM classifiers with different kernels\n",
    "def svmClassifier(kernel):\n",
    "    SVM_clf = SVC(random_state=42,kernel=kernel).fit(X_train,y_train)\n",
    "    return SVM_clf\n",
    "    \n",
    "SVM_clf_linear=LinearSVC(loss='hinge', penalty='l2', random_state=42).fit(X_train,y_train)\n",
    "# SVM_clf_linear=SGDClassifier(loss='hinge', penalty='l2', random_state=42).fit(X_train,y_train)\n",
    "y_predicted_SVM_linear=evaluateClassifier(classifier=SVM_clf_linear,model=\"Support vector machine classifier with linear kernel \",index=1)\n",
    "y_predicted_SVM_linear=changeShape(y_predicted_SVM_linear)\n",
    "\n",
    "SVM_clf_RBF=svmClassifier(kernel=\"rbf\")\n",
    "y_predicted_SVM_RBF=evaluateClassifier(classifier=SVM_clf_RBF,model=\"Support vector machine classifier with RBF kernel \",index=2)\n",
    "y_predicted_SVM_RBF=changeShape(y_predicted_SVM_RBF)\n",
    "\n",
    "SVM_clf_Poly=svmClassifier(kernel=\"poly\")\n",
    "y_predicted_SVM_Poly=evaluateClassifier(classifier=SVM_clf_Poly,model=\"Support vector machine classifier with polynomial kernel \",index=3)\n",
    "y_predicted_SVM_Poly=changeShape(y_predicted_SVM_Poly)\n",
    "\n",
    "SVM_clf_Sigmoid=svmClassifier(kernel=\"sigmoid\")\n",
    "y_predicted_SVM_Sigmoid=evaluateClassifier(classifier=SVM_clf_Sigmoid,model=\"Support vector machine classifier with sigmoid kernel \",index=4)\n",
    "y_predicted_SVM_Sigmoid=changeShape(y_predicted_SVM_Sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix of SVM for all kernels\n",
    "\n",
    "#### Linear SVM\n",
    "\n",
    "Confusion matrix for Linear SVM is shown in the below table. As it can be seen from the table, that the model has very high accuracy except for the category \"sci.space\". We can say that there is a minor confusion between \"sci.space\" and \"alt.atheism\" categories. During our testing, we have recieved 12 instances which are predicted \"alt.atheism\", but it were actually predicted as \"sci.space\". However, this number is very less and except this scenario, Linear SVM has a very good accuracy for all the other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of Linear SVM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.space</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    alt.atheism  talk.religion.misc  comp.graphics  sci.space\n",
       "alt.atheism                 212                   2              2          8\n",
       "talk.religion.misc            0                 295              2          0\n",
       "comp.graphics                 1                   9            296          1\n",
       "sci.space                    12                   6              2        169"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatrix(\"Linear SVM\",y_predicted_SVM_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF SVM\n",
    "\n",
    "Confusion matrix for RBF SVM is shown in the below table. As it can be seen from the table, that the model has very low accuracy. All the values are predicted as \"comp.graphics\" category regardless of original category. Hence, it has only 30% accuracy, because \"comp.graphics\" contributes to 30% of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of RBF SVM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.space</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    alt.atheism  talk.religion.misc  comp.graphics  sci.space\n",
       "alt.atheism                   0                   0            224          0\n",
       "talk.religion.misc            0                   0            297          0\n",
       "comp.graphics                 0                   0            307          0\n",
       "sci.space                     0                   0            189          0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatrix(\"RBF SVM\",y_predicted_SVM_RBF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly SVM\n",
    "\n",
    "Confusion matrix for Poly SVM is shown in the below table. As it can be seen from the table, that the model has very low accuracy. All the values are predicted as \"comp.graphics\" category regardless of original category. Hence, it has only 30% accuracy, because \"comp.graphics\" contributes to 30% of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of Poly SVM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.space</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    alt.atheism  talk.religion.misc  comp.graphics  sci.space\n",
       "alt.atheism                   0                   0            224          0\n",
       "talk.religion.misc            0                   0            297          0\n",
       "comp.graphics                 0                   0            307          0\n",
       "sci.space                     0                   0            189          0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatrix(\"Poly SVM\",y_predicted_SVM_Poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid SVM \n",
    "\n",
    "\n",
    "Confusion matrix for Sigmoid SVM is shown in the below table. As it can be seen from the table, that the model has very low accuracy. All the values are predicted as \"comp.graphics\" category regardless of original category. Hence, it has only 30% accuracy, because \"comp.graphics\" contributes to 30% of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of Sigmoid SVM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.space</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    alt.atheism  talk.religion.misc  comp.graphics  sci.space\n",
       "alt.atheism                   0                   0            224          0\n",
       "talk.religion.misc            0                   0            297          0\n",
       "comp.graphics                 0                   0            307          0\n",
       "sci.space                     0                   0            189          0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatrix(\"Sigmoid SVM\",y_predicted_SVM_Sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which algorithm has higher accuracy and why?\n",
    "\n",
    "### Comparing MultinomialNB and SVM\n",
    "\n",
    "We have compared the accuracies for MultinomialNB and SVM with various kenels. As it can be seen from the bar grpah, Linear SVM has higher accuracy than the MultinomialNB. However, all the other kernels for SVM have lower accuracies than MultinomialNB.\n",
    "\n",
    "### Why SVM is better?\n",
    "Multinomial is better at snippets of the documents, which means it has higher performance for small documents. However, SVM is better for full-length content, which means it has higher performance for large documents. In our example, it is a very large dataset of news articles. Approximate vocabulary count is 23000, which is very high. So, in this case SVM will perform better as compared to Multinomial NB.\n",
    "\n",
    "Other difference is that, Multinomial NB will treat words as independent. However, SVM treats the words as having some interaction between them. Hence, SVM takes into account the frequency of the words as well as how the words are related to each other. Therefore, in case of our dataset, it will have higher accuracy, because it not only focuses on the words frequency but also focuses on the interaction between words.\n",
    "\n",
    "\n",
    "Reference: https://stackoverflow.com/questions/35360081/naive-bayes-vs-svm-for-classifying-text-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# comparing the performance of all the models\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.bar(['MulinomialNB','Linear SVM','RBF SVM','Polynomial SVM','Sigmoid SVM'],evaluation[0:5],color=tuple([\"g\", \"b\",\"r\",\"y\",\"k\"]))\n",
    "plt.xlabel('Classifiers', fontsize=14)\n",
    "plt.ylabel('Accuracy Score', fontsize=14)\n",
    "plt.title(\"Bar graph of comparison between different models\", fontsize = 18,y=1.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-2d Considering nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing POS tagging on raw data\n",
    "\n",
    "We have performed POS tagging on the RAW data to get the part-of-speech for every word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387\n",
      "[('From', 'IN'), (':', ':'), ('healta', 'NN'), ('@', 'NN'), ('saturn.wwc.edu', 'NN'), ('(', '('), ('Tammy', 'NNP'), ('R', 'NNP'), ('Healy', 'NNP'), (')', ')'), ('Subject', 'NN'), (':', ':'), ('Re', 'NN'), (':', ':'), ('who', 'WP'), ('are', 'VBP'), ('we', 'PRP'), ('to', 'TO'), ('judge', 'VB'), (',', ','), ('Bobby', 'NNP'), ('?', '.'), ('Lines', 'NNS'), (':', ':'), ('38', 'CD'), ('Organization', 'NN'), (':', ':'), ('Walla', 'NNP'), ('Walla', 'NNP'), ('College', 'NNP'), ('Lines', 'NNP'), (':', ':'), ('38', 'CD'), ('In', 'IN'), ('article', 'NN'), ('<', '$'), ('1993Apr14.213356.22176', 'CD'), ('@', 'NNP'), ('ultb.isc.rit.edu', 'JJ'), ('>', 'NNP'), ('snm6394', 'NN'), ('@', 'NNP'), ('ultb.isc.rit.edu', 'NN'), ('(', '('), ('S.N', 'NNP'), ('.', '.'), ('Mozumder', 'NNP'), (')', ')'), ('writes', 'VBZ'), (':', ':'), ('>', 'NN'), ('From', 'IN'), (':', ':'), ('snm6394', 'NN'), ('@', 'NN'), ('ultb.isc.rit.edu', 'NN'), ('(', '('), ('S.N', 'NNP'), ('.', '.'), ('Mozumder', 'NNP'), (')', ')'), ('>', 'NN'), ('Subject', 'JJ'), (':', ':'), ('Re', 'NN'), (':', ':'), ('who', 'WP'), ('are', 'VBP'), ('we', 'PRP'), ('to', 'TO'), ('judge', 'VB'), (',', ','), ('Bobby', 'NNP'), ('?', '.'), ('>', 'NN'), ('Date', 'NN'), (':', ':'), ('Wed', 'NNP'), (',', ','), ('14', 'CD'), ('Apr', 'NNP'), ('1993', 'CD'), ('21:33:56', 'CD'), ('GMT', 'NNP'), ('>', 'NN'), ('In', 'IN'), ('article', 'NN'), ('<', 'NNP'), ('healta.56.734556346', 'NN'), ('@', 'NNP'), ('saturn.wwc.edu', 'NN'), ('>', 'NNP'), ('healta', 'NN'), ('@', 'NNP'), ('saturn.wwc.edu', 'NN'), ('(', '('), ('TAMMY', 'NNP'), ('R', 'NNP'), ('HEALY', 'NNP'), (')', ')'), ('writes', 'VBZ'), (':', ':'), ('>', 'NN'), ('>', 'NN'), ('Bobby', 'NNP'), (',', ','), ('>', 'NNP'), ('>', 'NNP'), ('>', 'NNP'), ('>', 'NNP'), ('I', 'PRP'), ('would', 'MD'), ('like', 'VB'), ('to', 'TO'), ('take', 'VB'), ('the', 'DT'), ('liberty', 'NN'), ('to', 'TO'), ('quote', 'VB'), ('from', 'IN'), ('a', 'DT'), ('Christian', 'JJ'), ('writer', 'NN'), ('named', 'VBN'), ('>', 'NNP'), ('>', 'NNP'), ('Ellen', 'NNP'), ('G.', 'NNP'), ('White', 'NNP'), ('.', '.'), ('I', 'PRP'), ('hope', 'VBP'), ('that', 'IN'), ('what', 'WP'), ('she', 'PRP'), ('said', 'VBD'), ('will', 'MD'), ('help', 'VB'), ('you', 'PRP'), ('to', 'TO'), ('edit', 'VB'), ('your', 'PRP$'), ('>', 'NN'), ('>', 'NN'), ('remarks', 'NNS'), ('in', 'IN'), ('this', 'DT'), ('group', 'NN'), ('in', 'IN'), ('the', 'DT'), ('future', 'NN'), ('.', '.'), ('>', 'JJ'), ('>', 'JJ'), ('>', 'NN'), ('>', 'NN'), (\"''\", \"''\"), ('Do', 'NNP'), ('not', 'RB'), ('set', 'VB'), ('yourself', 'PRP'), ('as', 'IN'), ('a', 'DT'), ('standard', 'NN'), ('.', '.'), ('Do', 'VBP'), ('not', 'RB'), ('make', 'VB'), ('your', 'PRP$'), ('opinions', 'NNS'), (',', ','), ('your', 'PRP$'), ('views', 'NNS'), ('>', 'VBP'), ('>', 'CD'), ('of', 'IN'), ('duty', 'NN'), (',', ','), ('your', 'PRP$'), ('interpretations', 'NNS'), ('of', 'IN'), ('scripture', 'NN'), (',', ','), ('a', 'DT'), ('criterion', 'NN'), ('for', 'IN'), ('others', 'NNS'), ('and', 'CC'), ('in', 'IN'), ('>', 'NNP'), ('>', 'NNP'), ('your', 'PRP$'), ('heart', 'NN'), ('condemn', 'VB'), ('them', 'PRP'), ('if', 'IN'), ('they', 'PRP'), ('do', 'VBP'), ('not', 'RB'), ('come', 'VB'), ('up', 'RP'), ('to', 'TO'), ('your', 'PRP$'), ('ideal', 'NN'), ('.', '.'), (\"''\", \"''\"), ('>', 'JJ'), ('>', 'NNP'), ('Thoughts', 'NNP'), ('Fromthe', 'NNP'), ('Mount', 'NNP'), ('of', 'IN'), ('Blessing', 'NNP'), ('p.', 'NN'), ('124', 'CD'), ('>', 'NN'), ('>', 'NNP'), ('>', 'NNP'), ('>', 'NNP'), ('I', 'PRP'), ('hope', 'VBP'), ('quoting', 'VBG'), ('this', 'DT'), ('does', 'VBZ'), (\"n't\", 'RB'), ('make', 'VB'), ('the', 'DT'), ('atheists', 'NNS'), ('gag', 'VBP'), (',', ','), ('but', 'CC'), ('I', 'PRP'), ('think', 'VBP'), ('Ellen', 'NNP'), ('White', 'NNP'), ('>', 'NNP'), ('>', 'NNP'), ('put', 'VBD'), ('it', 'PRP'), ('better', 'JJR'), ('than', 'IN'), ('I', 'PRP'), ('could', 'MD'), ('.', '.'), ('>', 'VB'), ('>', 'JJ'), ('>', 'NNP'), ('>', 'NNP'), ('Tammy', 'NNP'), ('>', 'NNP'), ('>', 'NNP'), ('Point', 'NNP'), ('?', '.'), ('>', 'NNP'), ('>', 'NNP'), ('Peace', 'NNP'), (',', ','), ('>', 'NNP'), ('>', 'NNP'), ('Bobby', 'NNP'), ('Mozumder', 'NNP'), ('>', 'NNP'), ('My', 'NNP'), ('point', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('you', 'PRP'), ('set', 'VBP'), ('up', 'RP'), ('your', 'PRP$'), ('views', 'NNS'), ('as', 'IN'), ('the', 'DT'), ('only', 'JJ'), ('way', 'NN'), ('to', 'TO'), ('believe', 'VB'), ('.', '.'), ('Saying', 'VBG'), ('that', 'IN'), ('all', 'DT'), ('eveil', 'NN'), ('in', 'IN'), ('this', 'DT'), ('world', 'NN'), ('is', 'VBZ'), ('caused', 'VBN'), ('by', 'IN'), ('atheism', 'NN'), ('is', 'VBZ'), ('ridiculous', 'JJ'), ('and', 'CC'), ('counterproductive', 'JJ'), ('to', 'TO'), ('dialogue', 'VB'), ('in', 'IN'), ('this', 'DT'), ('newsgroups', 'NN'), ('.', '.'), ('I', 'PRP'), ('see', 'VBP'), ('in', 'IN'), ('your', 'PRP$'), ('posts', 'NNS'), ('a', 'DT'), ('spirit', 'NN'), ('of', 'IN'), ('condemnation', 'NN'), ('of', 'IN'), ('the', 'DT'), ('atheists', 'NNS'), ('in', 'IN'), ('this', 'DT'), ('newsgroup', 'NN'), ('bacause', 'IN'), ('they', 'PRP'), (\"don'\", 'VBP'), ('t', 'JJ'), ('believe', 'VBP'), ('exactly', 'RB'), ('as', 'IN'), ('you', 'PRP'), ('do', 'VBP'), ('.', '.'), ('If', 'IN'), ('you', 'PRP'), (\"'re\", 'VBP'), ('here', 'RB'), ('to', 'TO'), ('try', 'VB'), ('to', 'TO'), ('convert', 'VB'), ('the', 'DT'), ('atheists', 'NNS'), ('here', 'RB'), (',', ','), ('you', 'PRP'), (\"'re\", 'VBP'), ('failing', 'VBG'), ('miserably', 'RB'), ('.', '.'), ('Who', 'WP'), ('wants', 'VBZ'), ('to', 'TO'), ('be', 'VB'), ('in', 'IN'), ('position', 'NN'), ('of', 'IN'), ('constantly', 'RB'), ('defending', 'VBG'), ('themselves', 'PRP'), ('agaist', 'JJ'), ('insulting', 'VBG'), ('attacks', 'NNS'), (',', ','), ('like', 'IN'), ('you', 'PRP'), ('seem', 'VBP'), ('to', 'TO'), ('like', 'VB'), ('to', 'TO'), ('do', 'VB'), ('?', '.'), ('!', '.'), ('I', 'PRP'), (\"'m\", 'VBP'), ('sorry', 'JJ'), ('you', 'PRP'), (\"'re\", 'VBP'), ('so', 'RB'), ('blind', 'IN'), ('that', 'IN'), ('you', 'PRP'), ('did', 'VBD'), (\"n't\", 'RB'), ('get', 'VB'), ('the', 'DT'), ('messgae', 'NN'), ('in', 'IN'), ('the', 'DT'), ('quote', 'NN'), (',', ','), ('everyone', 'NN'), ('else', 'RB'), ('has', 'VBZ'), ('seemed', 'VBN'), ('to', 'TO'), ('.', '.'), ('Tammy', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "# performing POS tagging on cleaned token of words\n",
    "posTagged_filtered_words=[]\n",
    "for i in range(len(tokens_words_for_newsgroups)):\n",
    "    posTagged_filtered_words.append(nltk.pos_tag(tokens_words_for_newsgroups[i]))\n",
    "print(len(posTagged_filtered_words))\n",
    "print(posTagged_filtered_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering only nouns before cleaning\n",
    "\n",
    "Out of all these POS tagged words, we will now find only the noun words. We have considered four categories of nouns: \"NN\", \"NNS\", \"NNP\", and \"NNPS.\" Hence, we have found out noun words for all 3387 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387\n",
      "['healta', '@', 'saturn.wwc.edu', 'Tammy', 'R', 'Healy', 'Subject', 'Re', 'Bobby', 'Lines', 'Organization', 'Walla', 'Walla', 'College', 'Lines', 'article', '@', '>', 'snm6394', '@', 'ultb.isc.rit.edu', 'S.N', 'Mozumder', '>', 'snm6394', '@', 'ultb.isc.rit.edu', 'S.N', 'Mozumder', '>', 'Re', 'Bobby', '>', 'Date', 'Wed', 'Apr', 'GMT', '>', 'article', '<', 'healta.56.734556346', '@', 'saturn.wwc.edu', '>', 'healta', '@', 'saturn.wwc.edu', 'TAMMY', 'R', 'HEALY', '>', '>', 'Bobby', '>', '>', '>', '>', 'liberty', 'writer', '>', '>', 'Ellen', 'G.', 'White', '>', '>', 'remarks', 'group', 'future', '>', '>', 'Do', 'standard', 'opinions', 'views', 'duty', 'interpretations', 'scripture', 'criterion', 'others', '>', '>', 'heart', 'ideal', '>', 'Thoughts', 'Fromthe', 'Mount', 'Blessing', 'p.', '>', '>', '>', '>', 'atheists', 'Ellen', 'White', '>', '>', '>', '>', 'Tammy', '>', '>', 'Point', '>', '>', 'Peace', '>', '>', 'Bobby', 'Mozumder', '>', 'My', 'point', 'views', 'way', 'eveil', 'world', 'atheism', 'newsgroups', 'posts', 'spirit', 'condemnation', 'atheists', 'newsgroup', 'atheists', 'position', 'attacks', 'messgae', 'quote', 'everyone']\n"
     ]
    }
   ],
   "source": [
    "# consider only nouns using posTagged words\n",
    "only_noun_words=[]\n",
    "words=[]\n",
    "for i in range(len(posTagged_filtered_words)):\n",
    "    words=[]\n",
    "    for word in posTagged_filtered_words[i]:\n",
    "        if word[1] in ('NN','NNS','NNP','NNPS'):\n",
    "            words.append(word[0])\n",
    "    only_noun_words.append(words)\n",
    "print(len(only_noun_words))\n",
    "print(only_noun_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the dataset\n",
    "\n",
    "For cleaning the dataset we have followed 3 steps same as above:\n",
    "\n",
    "- Remove stop words\n",
    "- Remove numbers and other non-letter characters\n",
    "- Stem the words\n",
    "\n",
    "We have tokenized each news article into only noun words. \"newsGroup_filtered_tokens_nouns\" list will contain only the noun words for each document. After that, for cleaning the dataset, we have removed stopwords, non-alphabetic characters and numbers. Moreover, we have also removed numbers. Thereafter, we have performed stemming on the words. For example, \"Game\" and \"Gaming\" represents the same word, so it can be considered as the single word. For stemming, we have user PorterStemmer from nltk library. After that, we have converted the stemmed word into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387\n",
      "Cleaned tokens:\n",
      "\n",
      " ['healta', 'tammy', 'r', 'healy', 'subject', 're', 'bobby', 'lines', 'organization', 'walla', 'walla', 'college', 'lines', 'article', 'mozumder', 'mozumder', 're', 'bobby', 'date', 'wed', 'apr', 'gmt', 'article', 'healta', 'tammy', 'r', 'healy', 'bobby', 'liberty', 'writer', 'ellen', 'white', 'remarks', 'group', 'future', 'do', 'standard', 'opinions', 'views', 'duty', 'interpretations', 'scripture', 'criterion', 'others', 'heart', 'ideal', 'thoughts', 'fromthe', 'mount', 'blessing', 'atheists', 'ellen', 'white', 'tammy', 'point', 'peace', 'bobby', 'mozumder', 'my', 'point', 'views', 'way', 'eveil', 'world', 'atheism', 'newsgroups', 'posts', 'spirit', 'condemnation', 'atheists', 'newsgroup', 'atheists', 'position', 'attacks', 'messgae', 'quote', 'everyone']\n"
     ]
    }
   ],
   "source": [
    "#  removing stopwords, number and other non-letter characters\n",
    "newsGroup_filtered_tokens_nouns=[]\n",
    "\n",
    "for i in range(len(only_noun_words)):\n",
    "    temp=[]\n",
    "    for w in only_noun_words[i]:\n",
    "        if ((w not in stop_words_english) and w.isalpha()):\n",
    "            temp.append(w.lower())\n",
    "    newsGroup_filtered_tokens_nouns.append(temp)\n",
    "# printing cleaned tokens of first news article\n",
    "print(len(newsGroup_filtered_tokens_nouns))\n",
    "print(\"Cleaned tokens:\\n\\n\",newsGroup_filtered_tokens_nouns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming the cleaned nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387\n",
      "Stemmed tokens\n",
      "\n",
      " ['healta', 'tammi', 'r', 'heali', 'subject', 're', 'bobbi', 'line', 'organ', 'walla', 'walla', 'colleg', 'line', 'articl', 'mozumd', 'mozumd', 're', 'bobbi', 'date', 'wed', 'apr', 'gmt', 'articl', 'healta', 'tammi', 'r', 'heali', 'bobbi', 'liberti', 'writer', 'ellen', 'white', 'remark', 'group', 'futur', 'do', 'standard', 'opinion', 'view', 'duti', 'interpret', 'scriptur', 'criterion', 'other', 'heart', 'ideal', 'thought', 'fromth', 'mount', 'bless', 'atheist', 'ellen', 'white', 'tammi', 'point', 'peac', 'bobbi', 'mozumd', 'my', 'point', 'view', 'way', 'eveil', 'world', 'atheism', 'newsgroup', 'post', 'spirit', 'condemn', 'atheist', 'newsgroup', 'atheist', 'posit', 'attack', 'messga', 'quot', 'everyon']\n"
     ]
    }
   ],
   "source": [
    "stemmed_news_group_nouns=[]\n",
    "for i in range(len(newsGroup_filtered_tokens_nouns)):\n",
    "    temp=[]\n",
    "    for w in newsGroup_filtered_tokens_nouns[i]:\n",
    "        temp.append(ps.stem(w))\n",
    "    stemmed_news_group_nouns.append(temp)\n",
    "    \n",
    "print(len(stemmed_news_group_nouns))       \n",
    "print(\"Stemmed tokens\\n\\n\",stemmed_news_group_nouns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healta tammi r heali subject re bobbi line organ walla walla colleg line articl mozumd mozumd re bobbi date wed apr gmt articl healta tammi r heali bobbi liberti writer ellen white remark group futur do standard opinion view duti interpret scriptur criterion other heart ideal thought fromth mount bless atheist ellen white tammi point peac bobbi mozumd my point view way eveil world atheism newsgroup post spirit condemn atheist newsgroup atheist posit attack messga quot everyon\n"
     ]
    }
   ],
   "source": [
    "# converting nouns into sentences\n",
    "for i in range(len(stemmed_news_group_nouns)):\n",
    "    stemmed_news_group_nouns[i]=\" \".join(stemmed_news_group_nouns[i])\n",
    "\n",
    "print(stemmed_news_group_nouns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words representation of nouns\n",
    "\n",
    "If we consider only nouns, the size of the vocabulary for bag-of-words has reduced to 19404. However, it was 23107 for all words in answer 2-c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3387, 19404)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bag of words representation of nouns\n",
    "count_vect = CountVectorizer()\n",
    "bagOfWords_noun= count_vect.fit_transform(stemmed_news_group_nouns)\n",
    "bagOfWords_noun.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF weighted vector of nouns\n",
    "\n",
    "Similarly, if we consider only nouns, the size of the vocabulary for TF-IDF weighted vector representation has reduced to 19404. However, it was 23107 for all words in answer 2-c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3387, 19404)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating tf-idf vector\n",
    "tfidf_transformer_noun = TfidfTransformer()\n",
    "tfidf_noun = tfidf_transformer.fit_transform(bagOfWords_noun)\n",
    "tfidf_noun.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data \n",
    "\n",
    "Splittng the dataset into training set and testing set as following :\n",
    "\n",
    "1. Training Set - 70%\n",
    "2. Testing Set - 30%\n",
    "\n",
    "Hence, 2370 documents are in training set and 1017 documents are in testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2370, 19404)\n",
      "(2370,)\n",
      "(1017, 19404)\n",
      "(1017,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_noun, newsgroups_data.target, test_size=0.30,random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "y_train=y_train.reshape((y_train.shape[0],1))\n",
    "y_test=y_test.reshape((y_test.shape[0],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MultinomialNB on nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_clf_noun= MultinomialNB().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating MultinomialNB \n",
    "\n",
    "For only nouns, the results for MultinomialNB has improved by approximately 2-3%. For example, for all the words MultinomialNB had 90% accuracy. However, for only noun words it has 92% approximate accuracy. Similarly, results for Precision, and Recall has improved in case of only nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of MultinomialNB classifier\n",
      "\n",
      "Training accuracy score: 0.958\n",
      "Test accuracy_score:0.920\n",
      "Precision: 0.928\n",
      "Recall: 0.920\n",
      "F1: 0.916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted_multinomialNB=evaluateClassifier(classifier=NB_clf_noun,model=\"MultinomialNB classifier\",index=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix of MultinomialNB\n",
    "\n",
    "As confusion matrix table below shows, we can say that if we consider only nouns, 44 instance of \"sci.shape\" are mis-classified as \"alt.atheism\". However, in case of all words, the number of wrongly-classified instances were 63. Hence, we can say that, it has improved in case of only nouns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of MultinomialNB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.space</th>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    alt.atheism  talk.religion.misc  comp.graphics  sci.space\n",
       "alt.atheism                 221                   0              2          1\n",
       "talk.religion.misc            0                 292              5          0\n",
       "comp.graphics                 2                   6            299          0\n",
       "sci.space                    44                   5             16        124"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatrix(\"MultinomialNB\",y_predicted_multinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating Linear SVM on nouns\n",
    "\n",
    "Performance of Linear SVM in case of onnly noun words is shown in below table. As it can be seen in the table, we can say that, the results are almost similar to that of all words. Hence, the accuracy of Linear SVM has not improves even if we consider only the noun words. The evaluation metrices remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Support vector machine classifier with linear kernel \n",
      "\n",
      "Training accuracy score: 0.994\n",
      "Test accuracy_score:0.954\n",
      "Precision: 0.954\n",
      "Recall: 0.954\n",
      "F1: 0.954\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shrey amin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "SVM_clf_linear_noun=LinearSVC(loss='hinge', penalty='l2', random_state=42).fit(X_train,y_train)\n",
    "y_predicted_SVM_linear=evaluateClassifier(classifier=SVM_clf_linear_noun,model=\"Support vector machine classifier with linear kernel \",index=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix of linear SVM\n",
    "\n",
    "As confusion matrix table below shows, we can say that even if we consider only nouns, the number of wrongly-classified instances remains the same and it is 12. Hence, we can say that, Linear SVM has the same results in case of all words and noun words both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of Linear SVM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt.atheism</th>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <th>comp.graphics</th>\n",
       "      <th>sci.space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.space</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    alt.atheism  talk.religion.misc  comp.graphics  sci.space\n",
       "alt.atheism                 209                   1              4         10\n",
       "talk.religion.misc            0                 295              2          0\n",
       "comp.graphics                 1                  10            295          1\n",
       "sci.space                    12                   5              1        171"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusionMatrix(\"Linear SVM\",y_predicted_SVM_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing performance on stemmed all words and stemmed noun words\n",
    "\n",
    "We have shown the comparison of Multinomial NB and Linear SVM in case of both noun words and all the words. As it can be seen in the table, the accuracy score of Multinomial Naive Bayes increases to approximately 92% for noun words from 90% for all words. Whereas, the accuracy score remains the same approximately (95%) in case of Linear SVM for both the noun words and all words case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score in both the approaches\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>Linear SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stemmed features</th>\n",
       "      <td>0.907571</td>\n",
       "      <td>0.955752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Noun features</th>\n",
       "      <td>0.920354</td>\n",
       "      <td>0.953786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MultinomialNB  Linear SVM\n",
       "Stemmed features       0.907571    0.955752\n",
       "Noun features          0.920354    0.953786"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing the performance with stemmed tokens and noun tokens\n",
    "evaluation_score_list=[0,0,0,0]\n",
    "evaluation_score_list[0]=evaluation[0]\n",
    "evaluation_score_list[1]=evaluation[5]\n",
    "evaluation_score_list[2]=evaluation[1]\n",
    "evaluation_score_list[3]=evaluation[6]\n",
    "comparison_df=pd.DataFrame([[evaluation[0],evaluation[1]],[evaluation[5],evaluation[6]]],index=[\"Stemmed features\",\"Noun features\"],columns=[\"MultinomialNB\",\"Linear SVM\"])\n",
    "print(\"Accuracy score in both the approaches\")\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Graph for comparison\n",
    "\n",
    "We have also shown the bar graph for both Multinomial NB and Linear SVM in case of both the noun words and all words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.bar(['MulinomialNB','MulinomialNB_Noun','Linear SVM','Linear SVM_Noun'],evaluation_score_list,color=tuple([\"g\", \"b\",\"r\",\"y\",\"k\"]))\n",
    "plt.xlabel('Classifiers', fontsize=14)\n",
    "plt.ylabel('Accuracy Score', fontsize=14)\n",
    "plt.title(\"Bar graph of comparison between different models with only stemmed features vs stemmed noun features\", fontsize = 18,y=1.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing size of vocabularies\n",
    "\n",
    "As discussed above, the size of vocabulary for all words was 23107 and for noun words it was 19404. We have plotted the bar graph to show the comparison between both. Moreover, with less number of features the perfromance of both the models does not decrease. So, its better if we consider only nouns as the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features in stemming:  23107\n",
      "Total features in considering only nouns:  19404\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  comparing vocabularies\n",
    "print(\"Total features in stemming: \",bagOfWords.shape[1])\n",
    "print(\"Total features in considering only nouns: \",bagOfWords_noun.shape[1])\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.bar(['Stemmed Features','Noun Features'],[bagOfWords.shape[1],bagOfWords_noun.shape[1]],color=tuple([\"g\", \"b\",\"r\",\"y\",\"k\"]))\n",
    "plt.xlabel('Approach', fontsize=14)\n",
    "plt.ylabel('Total Vocabularies', fontsize=14)\n",
    "plt.title(\"Bar graph of comparison between of total vocabularies\", fontsize = 18,y=1.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Tutorial 6\n",
    "- Collocations : https://medium.com/@nicharuch/collocations-identifying-phrases-that-act-like-individual-words-in-nlp-f58a93a2f84a\n",
    "- Bag-of-words representation : https://machinelearningmastery.com/gentle-introduction-bag-words-model/\n",
    "- TF-IDF weighted vector representation : https://www.commonlounge.com/discussion/99e86c9c15bb4d23a30b111b23e7b7b1\n",
    "- SVM with different kernels : https://scikit-learn.org/stable/modules/svm.html\n",
    "- Comparison between Multinomial NB and SVM - https://stackoverflow.com/questions/35360081/naive-bayes-vs-svm-for-classifying-text-data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
